{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import yfinance as yf\nimport pandas as pd\n\ndef get_stock_data(ticker, start_date, end_date):\n    \"\"\"\n    Fetches stock data for the given ticker symbol within the specified time period.\n\n    Parameters:\n        ticker (str): Ticker symbol of the stock.\n        start_date (str): Start date in the format 'YYYY-MM-DD'.\n        end_date (str): End date in the format 'YYYY-MM-DD'.\n\n    Returns:\n        DataFrame: Stock data for the specified time period.\n    \"\"\"\n    stock_data = yf.download(ticker, start=start_date, end=end_date)\n    return stock_data\n\n# Specify the date range\nstart_date = '2010-01-01'  # Example start date\nend_date = '2024-01-01'    # Example end date\n\n# Fetch stock data for BMW within the specified time period\ndf= get_stock_data('BMW.DE', start_date, end_date)\n\n# Display the stock data\ndisplay(df)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"id":"KqqVgjHeBNAD","outputId":"a1033efc-aaf6-44c0-ce13-59818698b041"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.line(y='Close')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440},"id":"M8FxpHkzBjC9","outputId":"a9b67a29-c1cf-47aa-a744-98e60ecfa46d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Tomorrow'] = df['Close'].shift(-1)","metadata":{"id":"_C1I1cT1CmI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Target'] = (df['Tomorrow'] > df['Close']).astype(int)\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"2bG4FjAICABv","outputId":"43b1c0c4-d20c-48df-99e3-2cb9862c6ece"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.iloc[:-100]\ntest = df.iloc[-100:]\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier (n_estimators=100, min_samples_split=100, random_state=1)\npredictors = ['Close', 'Volume', 'Open', 'High', 'Low']\nmodel.fit(train[predictors], train['Target'])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"qhJ24SkNDIn9","outputId":"6cd4e906-5879-4c30-9d6e-5bf16f6a6ce5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score\npreds = model.predict(test[predictors])\nimport pandas as pd\npreds = pd.Series(preds, index=test.index)","metadata":{"id":"u_XVincTC4Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(test['Target'], preds)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTPOfXWoEJOD","outputId":"2957ba28-b078-4073-bd3f-02d16119a229"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = pd.concat([test['Target'], preds], axis=1)\ncombined.plot()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"id":"DdC5vI6sERAs","outputId":"dc2e2387-aef1-4634-e004-3d9485a7ff84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def backtest(data, model, predictors, start=2500, step=250):\n    all_predictions = []\n\n    for i in range(start, data.shape[0], step):\n        train = data.iloc[0:i].copy()\n        test = data.iloc[i:(i+step)].copy()\n        predictions = predict(train, test, predictors, model)\n        all_predictions.append(predictions)\n\n    return pd.concat(all_predictions)","metadata":{"id":"U5ecO9zKEbB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(train, test, predictors, model):\n    model.fit(train[predictors], train[\"Target\"])\n    preds = model.predict(test[predictors])\n    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n    combined = pd.concat([test[\"Target\"], preds], axis=1)\n    return combined","metadata":{"id":"kZxx0yv9Epdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npredictions = backtest(df, model, predictors)\npredictions[\"Predictions\"].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsTNkyJwErPN","outputId":"2560cd00-238a-4c0b-b213-af779d765b95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(predictions[\"Target\"], predictions[\"Predictions\"])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6y3iPAi1EvB3","outputId":"b7ba16e6-d983-46b1-9c45-adf79832f536"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[\"Target\"].value_counts() / predictions.shape[0]\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whze0b6GEwYh","outputId":"b84aa67b-42cd-4f20-a671-7ef39e8a61aa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"horizons = [2,5,60,250,1000]\nnew_predictors = []\n\nfor horizon in horizons:\n    rolling_averages = df.rolling(horizon).mean()\n\n    ratio_column = f\"Close_Ratio_{horizon}\"\n    df[ratio_column] = df[\"Close\"] / rolling_averages[\"Close\"]\n\n    trend_column = f\"Trend_{horizon}\"\n    df[trend_column] = df.shift(1).rolling(horizon).sum()[\"Target\"]\n\n    new_predictors+= [ratio_column, trend_column]","metadata":{"id":"YYQS6M4fEyEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=df.columns[df.columns != \"Tomorrow\"])\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":648},"id":"lHvVyIwfE19m","outputId":"b3d819a5-cc05-4c82-f5d6-c58050953bb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=200, min_samples_split=50, random_state=1)\ndef predict(train, test, predictors, model):\n    model.fit(train[predictors], train[\"Target\"])\n    preds = model.predict_proba(test[predictors])[:,1]\n    preds[preds >=.6] = 1\n    preds[preds <.6] = 0\n    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n    combined = pd.concat([test[\"Target\"], preds], axis=1)\n    return combined\npredictions = backtest(df, model, new_predictors)\npredictions[\"Predictions\"].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJFlwG39FAeU","outputId":"37252ba8-2f43-4b33-bf00-56b058cc261a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(predictions[\"Target\"], predictions[\"Predictions\"])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e4AkKdoFER4","outputId":"ec6f7297-c887-4304-cf2c-c3476ba67bde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[\"Target\"].value_counts() / predictions.shape[0]\npredictions","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CPdbvsZvFFrN","outputId":"8c760c2a-af76-4ee6-bd07-1ef2cf7f9960"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nlabel_encoder = LabelEncoder()\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers, Sequential\n","metadata":{"id":"2x66p3F5GFnY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df.drop([\"Tomorrow\", \"Target\"], axis=1)  # Exclude the 'Tomorrow' column and 'Target' column from predictors\nY_train = df[\"Target\"]\n\n# Split the data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.20)\n\n# Assuming your input data has timesteps\ntimesteps = x_train.shape[1]  # Number of timesteps\nfeatures = x_train.shape[2] if len(x_train.shape) > 2 else 1  # Number of features per timestep\n\n# Define the model architecture\nmodel = Sequential([\n    layers.Input(shape=(timesteps, features)),  # Input shape with timesteps and features\n\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),  # Add Dropout to prevent overfitting\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=False)),\n    layers.Dropout(0.2),\n\n    layers.Dense(1, activation='sigmoid')  # Output layer\n])\n\n# Define optimizer and compile the model\nlearning_rate = 0.00001\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define Early Stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with Early Stopping\nhistory = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3XQm2xwGHRU","outputId":"9b1e8dc3-45a4-4a16-87f4-10269306020b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"id":"nhETJREUG74i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#df = pd.read_csv('https://raw.githubusercontent.com/umar-farooq-khan/m-en-dataset/main/M-En%20Dataset.csv')\ny = df['target'].replace('Normal', 0).replace('Anomaly', 1)\nX = df.drop(['target', df.columns[0]], axis=1)\nx_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.20)\n\nfrom tensorflow.keras import layers, Sequential\n\n# Assuming your input data has timesteps\ntimesteps = x_train.shape[1]  # Number of timesteps\nfeatures = x_train.shape[2] if len(x_train.shape) > 2 else 1  # Number of features per timestep\nmodel = Sequential([\n    layers.Input(shape=(timesteps, features)),  # Input shape with timesteps and features\n\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),  # Add Dropout to prevent overfitting\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.LSTM(400, return_sequences=True)),\n    layers.Dropout(0.2),\n    layers.Bidirectional(layers.GRU(400, return_sequences=False)),\n    layers.Dropout(0.2),\n\n    layers.Dense(1, activation='sigmoid')  # Output layer\n])\n\n# Define optimizer and compile the model\nlearning_rate = 0.00001\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define Early Stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with Early Stopping\nhistory = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"id":"gS04N9vEA6Bt"},"execution_count":null,"outputs":[]}]}